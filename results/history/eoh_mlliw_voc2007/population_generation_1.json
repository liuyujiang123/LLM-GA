{
     "algorithm": "```",
     "code": "import torch\nfrom torch.autograd import Variable\n\ndef gen_adv_examples(self, org_img, model, target):\n    adv_img = Variable(org_img.data, requires_grad=True)\n    accumulated_grad = torch.zeros_like(org_img)\n    for _ in range(self.maxiter):\n        grad = self.get_gradient(adv_img, model, target)\n        normalized_grad = grad / (torch.norm(grad, p=2) + 1e-10)\n        accumulated_grad += normalized_grad\n        adv_img = adv_img + self.alpha * accumulated_grad.sign()\n        perturbation = torch.clamp(adv_img - org_img, min=-self.epsilon, max=self.epsilon)\n        adv_img = org_img + perturbation\n        adv_img = self.clip_adv(org_img, adv_img)\n    return adv_img",
     "objective": 559.07599,
     "other_inf": null
}