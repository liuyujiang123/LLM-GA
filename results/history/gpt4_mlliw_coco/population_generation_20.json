{
     "algorithm": "The algorithm utilizes a sinusoidal adaptive step size with integrated noise scaling and random directional exploration for generating adversarial examples by iteratively refining perturbations.",
     "code": "import torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\n# {The algorithm utilizes a sinusoidal adaptive step size with integrated noise scaling and random directional exploration for generating adversarial examples by iteratively refining perturbations.}\n\ndef gen_adv_examples(org_img, target_model, target):\n    maxiter = 30\n    epsilon = 0.3\n    alpha = 0.002\n    decay_factor = 0.85\n    noise_scale = 0.02\n    loss_func = nn.BCELoss(reduction='mean')\n\n    # Random Initialization within epsilon-ball\n    adv_img = org_img + torch.empty_like(org_img).uniform_(-epsilon, epsilon)\n    adv_img = torch.clamp(adv_img, 0, 1)\n    adv_img = Variable(adv_img.data, requires_grad=True)\n\n    # Momentum and noise integration\n    momentum = torch.zeros_like(org_img)\n\n    for i in range(maxiter):\n        output = target_model(adv_img)\n        loss = -loss_func(output, target.float())\n\n        if adv_img.grad is not None:\n            adv_img.grad.data.zero_()\n\n        loss.backward()\n\n        # Noise scaling and random directional exploration\n        grad = adv_img.grad / (torch.norm(adv_img.grad, p=2, dim=[1,2,3], keepdim=True) + 1e-8)\n        grad *= (1 + noise_scale * torch.randn_like(grad))\n        momentum = decay_factor * momentum + grad\n\n        # Sinusoidal adaptive step size\n        sin_alpha = alpha * (1 + torch.sin(torch.tensor(i / maxiter * 3.14159)))\n\n        # Update adversarial image\n        adv_img = adv_img + sin_alpha * momentum.sign()\n        adv_img = torch.clamp(adv_img, org_img - epsilon, org_img + epsilon)\n        adv_img = torch.clamp(adv_img, 0, 1)\n        adv_img = Variable(adv_img.data, requires_grad=True)\n\n    return adv_img",
     "objective": 198.94012,
     "other_inf": null
}